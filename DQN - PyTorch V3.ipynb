{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "import gym\n",
    "from collections import deque\n",
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "import pdb\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "GAMMA = 0.99\n",
    "NUM_NODES = 24\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 50000\n",
    "MIN_REPLAY_SIZE = 1000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.02\n",
    "EPSILON_DECAY = 10000\n",
    "TARGET_UPDATE_FREQ = 1000\n",
    "LEARNING_RATE = 5e-4\n",
    "MAX_STEPS = 200000\n",
    "\n",
    "# Regularization Coefficient\n",
    "REGULARIZATION_COEFFICIENT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_matrix = []\n",
    "observations_t = None\n",
    "new_observations_t = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default loss function - mean squared error\n",
    "\n",
    "def default_loss_mse(y_true, y_pred):\n",
    "    \n",
    "    loss = torch.mean(torch.square(y_true-y_pred))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function - implements explicit DR3 regularizer\n",
    "\n",
    "# add dot product between each state action and subsequent oneâ€™s feature vector to loss\n",
    "def dr3(y_true, y_pred):\n",
    "    \n",
    "    global observations_t, new_observations_t\n",
    "    \n",
    "    loss = torch.mean(torch.square(y_true-y_pred))\n",
    "    \n",
    "    curr_states = online_net.get_phi(observations_t)\n",
    "    next_states = online_net.get_phi(new_observations_t)\n",
    "    \n",
    "    # pdb.set_trace()\n",
    "    \n",
    "    loss += REGULARIZATION_COEFFICIENT * torch.sum(torch.sum(curr_states * next_states, axis=1)) / BATCH_SIZE\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function - random dot product from phi matrix\n",
    "\n",
    "# randomly sample two vectors from the phi matrix and add dot product of those vectors to loss\n",
    "def random_dot(y_true, y_pred):\n",
    "\n",
    "    global phi_matrix\n",
    "    \n",
    "    loss = torch.mean(torch.square(y_true-y_pred))\n",
    "    \n",
    "    # Explicit Regularization\n",
    "    if ((phi_matrix is not None) and (len(phi_matrix) > 1)):\n",
    "        \n",
    "        v1 = phi_matrix[random.randrange(len(phi_matrix))]\n",
    "        v2 = phi_matrix[random.randrange(len(phi_matrix))]\n",
    "        \n",
    "        # pdb.set_trace()\n",
    "        \n",
    "        loss += REGULARIZATION_COEFFICIENT * torch.dot(torch.tensor(v1), torch.tensor(v2))\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function - implements regulizer based on min/max singular values in phi matrix\n",
    "\n",
    "# add difference between max entry in phi matrix ** 2 and min entry in phi matrix ** 2 to loss\n",
    "def phi_penalty(y_true, y_pred):\n",
    "    \n",
    "    global phi_matrix\n",
    "    \n",
    "    loss = torch.mean(torch.square(y_true-y_pred))\n",
    "    \n",
    "    # Explicit Regularization\n",
    "    if ((phi_matrix is not None) and (len(phi_matrix) > 0)):\n",
    "        \n",
    "        minimum = min([min(value) for value in phi_matrix])\n",
    "        maximum = max([max(value) for value in phi_matrix])\n",
    "        \n",
    "        # pdb.set_trace()\n",
    "        \n",
    "        loss += REGULARIZATION_COEFFICIENT * torch.sub(maximum**2, minimum**2)\n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network class\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        super().__init__()        \n",
    "        in_features = int(np.prod(env.observation_space.shape))     \n",
    "        # Neural Network\n",
    "        self.layer1 = nn.Linear(in_features, NUM_NODES)\n",
    "        self.layer2 = nn.ReLU()\n",
    "        self.layer3 = nn.ReLU()\n",
    "        self.layer4 = nn.Linear(NUM_NODES, env.action_space.n)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer4(self.layer3(self.layer2(self.layer1(x))))\n",
    "    \n",
    "    def act(self, obs):\n",
    "        obs_t = torch.as_tensor(obs, dtype=torch.float32)\n",
    "        q_values = self(obs_t.unsqueeze(0))\n",
    "        \n",
    "        max_q_index = torch.argmax(q_values, dim=1)[0]\n",
    "        action = max_q_index.detach().item()\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def get_phi(self, x):\n",
    "        return self.layer3(self.layer2(self.layer1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create OpenAI Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create environment\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "replay_buffer = deque(maxlen=BUFFER_SIZE)\n",
    "reward_buffer = deque([0.0], maxlen=100)\n",
    "\n",
    "all_ranks = []\n",
    "last_100_ranks = deque([], maxlen=100)\n",
    "all_rewards = []\n",
    "\n",
    "episode_reward = 0.0\n",
    "\n",
    "online_net = Network(env)\n",
    "target_net = Network(env)\n",
    "\n",
    "target_net.load_state_dict(online_net.state_dict())\n",
    "\n",
    "optimizer = torch.optim.Adam(online_net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(MIN_REPLAY_SIZE):\n",
    "    \n",
    "    action = env.action_space.sample()\n",
    "    new_obs, reward, done, info = env.step(action)\n",
    "    transition = (obs, action, reward, done, new_obs)\n",
    "    replay_buffer.append(transition)\n",
    "    obs = new_obs\n",
    "    \n",
    "    if done:\n",
    "        obs = env.reset() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_loss_mse\n",
    "# dr3\n",
    "# random_dot\n",
    "# phi_penalty\n",
    "\n",
    "loss_function = dr3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "for step in range(1, MAX_STEPS+1):\n",
    "    \n",
    "    epsilon = np.interp(step, [0, EPSILON_DECAY], [EPSILON_START, EPSILON_END])\n",
    "    \n",
    "    rng = random.random()\n",
    "    if rng <= epsilon:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = online_net.act(obs)\n",
    "    \n",
    "    new_obs, reward, done, _ = env.step(action)\n",
    "    transition = (obs, action, reward, done, new_obs)\n",
    "    replay_buffer.append(transition)\n",
    "    obs = new_obs\n",
    "    \n",
    "    episode_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "        reward_buffer.append(episode_reward)\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0.0\n",
    "        \n",
    "    # Start Gradient Step   \n",
    "    transitions = random.sample(replay_buffer, BATCH_SIZE)\n",
    "    \n",
    "    observations = np.asarray([t[0] for t in transitions])\n",
    "    actions = np.asarray([t[1] for t in transitions])\n",
    "    rewards = np.asarray([t[2] for t in transitions])\n",
    "    dones = np.asarray([t[3] for t in transitions])\n",
    "    new_observations = np.asarray([t[4] for t in transitions])\n",
    "    \n",
    "    observations_t = torch.as_tensor(observations, dtype=torch.float32)\n",
    "    actions_t = torch.as_tensor(actions, dtype=torch.int64).unsqueeze(-1)\n",
    "    rewards_t = torch.as_tensor(rewards, dtype=torch.float32).unsqueeze(-1)\n",
    "    dones_t = torch.as_tensor(dones, dtype=torch.float32).unsqueeze(-1)\n",
    "    new_observations_t = torch.as_tensor(new_observations, dtype=torch.float32)\n",
    "    \n",
    "    # Compute Targets\n",
    "    target_q_values = target_net(new_observations_t)\n",
    "    max_target_q_values = target_q_values.max(dim=1, keepdim=True)[0]\n",
    "    \n",
    "    targets = rewards_t + GAMMA * (1 - dones_t) * max_target_q_values\n",
    "    \n",
    "    # Compute Loss\n",
    "    q_values = online_net(observations_t)\n",
    "    action_q_values = torch.gather(input=q_values, dim=1, index=actions_t)\n",
    "    loss = loss_function(action_q_values, targets)\n",
    "    \n",
    "    # Gradient Descent\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Compute Phi Matrix\n",
    "    phi_matrix = []\n",
    "    phi_matrix = online_net.get_phi(observations_t)\n",
    "    phi_matrix = phi_matrix.cpu().detach().numpy()\n",
    "    rank = np.linalg.matrix_rank(phi_matrix)\n",
    "    all_ranks.append(rank)\n",
    "    last_100_ranks.append(rank)\n",
    "    \n",
    "    # Update Target Network\n",
    "    if step % TARGET_UPDATE_FREQ == 0:\n",
    "        target_net.load_state_dict(online_net.state_dict())\n",
    "        \n",
    "    # Logging\n",
    "    PRINT_LOG = False\n",
    "    if PRINT_LOG and step % 1000 == 0:\n",
    "        print()\n",
    "        print(\"Step:\", step)\n",
    "        print(\"Average Reward:\", np.mean(reward_buffer))\n",
    "        print(\"Average Rank:\", np.mean(last_100_ranks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Collapse Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.4 9.45 9.95\n"
     ]
    }
   ],
   "source": [
    "# max, min, and range rank\n",
    "\n",
    "starting_rank = np.mean(all_ranks[:10])\n",
    "final_rank = np.mean(all_ranks[-20:])\n",
    "print(starting_rank, final_rank, starting_rank-final_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(list(range(len(all_ranks))), all_ranks)\n",
    "\n",
    "plt.ylim(0, 25) # set range for y axis\n",
    "plt.ylabel('rank') # set the label for y axis\n",
    "plt.xlabel('train step') # set the label for x-axis\n",
    "plt.title(\"Rank Collapse\") # set the title of the graph\n",
    "\n",
    "plt.show() # display the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0\n"
     ]
    }
   ],
   "source": [
    "# max reward\n",
    "\n",
    "print(np.mean(all_rewards[-10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.scatter(list(range(len(all_rewards))), all_rewards)\n",
    "\n",
    "plt.ylim(0, 200) # set range for y axis\n",
    "plt.ylabel('reward') # set the label for y axis\n",
    "plt.xlabel('episode') # set the label for x-axis\n",
    "plt.title(\"Episode Reward\") # set the title of the graph\n",
    "\n",
    "plt.show() # display the graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
