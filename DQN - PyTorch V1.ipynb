{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Implementation - PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import pdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed) \n",
    "torch.manual_seed(0)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables used for custom loss functions \n",
    "\n",
    "global current_state_vector, next_state_vector # for dr3 regularizer\n",
    "global phi_matrix, ranks # for explicit regularizers\n",
    "phi_matrix = []\n",
    "ranks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default loss function - mean squared error\n",
    "\n",
    "def default_loss(y_true, y_pred, phi_matrix):\n",
    "    \n",
    "    loss = torch.mean(torch.square(y_true-y_pred))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function - implements explicit regularizer DR3\n",
    "\n",
    "c_0 = 0.01 # dr3 coefficient\n",
    "\n",
    "# add dot product between each state action and subsequent oneâ€™s feature vector to loss\n",
    "def dr3(y_true, y_pred, phi_matrix):\n",
    "    \n",
    "    global current_state_vector, next_state_vector \n",
    "    \n",
    "    loss = torch.mean(torch.square(y_true-y_pred))\n",
    "    \n",
    "    # Explicit Regularization\n",
    "    if (isinstance(current_state_vector, list) and isinstance(next_state_vector, list)):\n",
    "        # take dot product of curr and next state\n",
    "        loss += c_0 * np.dot(np.array(current_state_vector), np.array(next_state_vector))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function - random dot product from phi matrix\n",
    "\n",
    "c = 0.01 # coefficient\n",
    "\n",
    "# randomly sample two vectors from the phi matrix and add dot product of those vectors to loss\n",
    "def random_dot(y_true, y_pred, phi_matrix):\n",
    "\n",
    "    #global phi_matrix\n",
    "    \n",
    "    loss = torch.mean(torch.square(y_true-y_pred))\n",
    "    \n",
    "    # Explicit Regularization\n",
    "    if ((phi_matrix is not None) and (len(phi_matrix) > 1)):\n",
    "        \n",
    "        v1 = phi_matrix[random.randrange(len(phi_matrix))]\n",
    "        v2 = phi_matrix[random.randrange(len(phi_matrix))]\n",
    "        \n",
    "        loss += c * np.dot(np.array(v1), np.array(v2))\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function - implements regulizer based on min/max singular values in phi matrix\n",
    "\n",
    "alpha = 0.01 # tradeoff factor\n",
    "\n",
    "# add difference between max entry in phi matrix ** 2 and min entry in phi matrix ** 2 to loss\n",
    "def phi_penalty(y_true, y_pred, phi_matrix):\n",
    "    \n",
    "    loss = torch.mean(torch.square(y_true-y_pred))\n",
    "    \n",
    "    # Explicit Regularization\n",
    "    if ((phi_matrix is not None) and (len(phi_matrix) > 0)):\n",
    "        minimum = min([min(value) for value in phi_matrix])\n",
    "        maximum = max([max(value) for value in phi_matrix])\n",
    "        loss += alpha * (maximum**2 - minimum**2)\n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(4, 24)\n",
    "        self.layer2 = nn.Conv2d(24, 24)\n",
    "        self.layer3 = nn.Conv2d(24, 24)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(24, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        return self.head(x.view(x.size(0), -1))\n",
    "    \n",
    "    def get_phi(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        n, k, w, h = x.shape\n",
    "        features = x.view(n, k*w*h)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'kernel_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5348f6c86e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mn_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpolicy_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mtarget_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-b7d770d7c57d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, h, w, outputs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDQN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'kernel_size'"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    \n",
    "    global phi_matrix, ranks\n",
    "    global current_state_vector, next_state_vector\n",
    "    \n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    next_states = torch.cat(batch.next_state)\n",
    "    \n",
    "    next_state_phi = get_phi(next_states)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute loss\n",
    "    loss = default_loss(state_action_values, expected_state_action_values.unsqueeze(1), phi_matrix)\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    \n",
    "    phi_matrix = policy_net.get_phi(state_batch) # 32 (batch size) x 32 (nodes)\n",
    "    phi_matrix = phi_matrix.cpu().detach().numpy()\n",
    "    rank = np.linalg.matrix_rank(phi_matrix)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    #pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (120x90 and 4x16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-bac06f688d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Select and perform an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-5348f6c86e5c>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# second column on max result is index of where max element was\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# found, so we pick action with the larger expected reward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-ffb68a8d25f9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (120x90 and 4x16)"
     ]
    }
   ],
   "source": [
    "num_episodes = 25\n",
    "for i_episode in range(num_episodes):\n",
    "    \n",
    "    print(\"Episode:\", i_episode+1)\n",
    "    \n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            # plot_durations()\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete!')\n",
    "env.render()\n",
    "env.close()\n",
    "# plt.ioff()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank Collapse: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot rank collapse\n",
    "\n",
    "print(\"Rank Collapse: \" + str(max(ranks) - min(ranks)))\n",
    "\n",
    "plt.scatter(list(range(len(ranks))), ranks)\n",
    "\n",
    "plt.ylabel('rank') # set the label for y axis\n",
    "plt.xlabel('train iteration') # set the label for x-axis\n",
    "plt.title(\"Rank Collapse\") # set the title of the graph\n",
    "\n",
    "plt.show() # display the graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
